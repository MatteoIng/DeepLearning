{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brain MRI Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install d2l==1.0.0a1.post0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 15:23:35.099442: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-20 15:23:35.871249: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-20 15:23:35.871328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-20 15:23:35.871336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "from glob import glob\n",
    "from d2l import tensorflow as d2l\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import keras.layers as layer\n",
    "from PIL import Image\n",
    "# For GPU\n",
    "from numba import jit,cuda"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione di una specifica struttura del dataset per UNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mi serve per salvare il path delle immagini\n",
    "img = []\n",
    "\n",
    "# Percorso per prendere tutte le maschere e non le immagini\n",
    "msk = glob('C:/Users/MATTEO/Desktop/Programmi/Python/DeepLearning/ProgettoDeep/Brain_MRI/*/*_mask*')\n",
    "\n",
    "# Scorro le maschere e rimuovo mask per la corrispondente immagine associata\n",
    "for i in msk:\n",
    "    img.append(i.replace('_mask',''))\n",
    "\n",
    "\n",
    "for i in range(len(msk)):\n",
    "    # sposto immagine\n",
    "    im=Image.open(img[i])\n",
    "    ms=Image.open(msk[i])\n",
    "    im.save(\"C:/Users/MATTEO\\\\Desktop\\\\Programmi\\\\Python\\\\DeepLearning\\\\ProgettoDeep\\\\DsDL\\\\images\\\\prova\"+str(i)+\".tif\")\n",
    "    ms.save(\"C:\\\\Users\\\\MATTEO\\\\Desktop\\\\Programmi\\\\Python\\\\DeepLearning\\\\ProgettoDeep\\\\DsDL\\\\masks\\\\0\\\\prova\"+str(i)+\".tif\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento dei percorsi delle immagini per UNET e ResUnet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_path():\n",
    "    print(\"Load path..\")\n",
    "\n",
    "    # Mi serve per salvare il path delle immagini\n",
    "    image_files = []\n",
    "\n",
    "    # Percorso per prendere tutte le maschere e non le immagini\n",
    "    image_masks = glob('C:/Users/MATTEO/Desktop/Programmi/Python/DeepLearning/ProgettoDeep/Brain_MRI/*/*_mask*')\n",
    "\n",
    "    # Scorro le maschere e rimuovo mask per la corrispondente immagine associata\n",
    "    for i in image_masks:\n",
    "        image_files.append(i.replace('_mask',''))\n",
    "        \n",
    "    return image_files,image_masks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento delle immagini + Data augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img():\n",
    "    # prendo tutti i path di immagini\n",
    "    img,msk=load_path()\n",
    "    print(\"Load image..\")\n",
    "\n",
    "    # np array per immgini e maschere\n",
    "    imlst=np.zeros((len(img*4),256,256,3),dtype=np.uint8)\n",
    "    mslst=np.zeros((len(msk*4),256,256),dtype=np.bool_)\n",
    "    \n",
    "    # scorro i path e prendo immagini\n",
    "    index=0\n",
    "    j=0\n",
    "    with d2l.try_gpu():\n",
    "        for i in range(len(img)):\n",
    "            index=index+1\n",
    "            print(index)\n",
    "\n",
    "            # carico immagine\n",
    "            im=Image.open(img[i])\n",
    "\n",
    "            # Data augmentation\n",
    "            imRotate=im.rotate(90)\n",
    "            imFlippedLR=im.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "            imFlippedTB=im.transpose(Image.Transpose.FLIP_TOP_BOTTOM)\n",
    "\n",
    "            # carico maschera\n",
    "            ms=Image.open(msk[i])\n",
    "            msRotate=ms.rotate(90)\n",
    "            msFlippedLR=ms.transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "            msFlippedTB=ms.transpose(Image.Transpose.FLIP_TOP_BOTTOM)\n",
    "            \n",
    "            # metto nell'nparray\n",
    "            imlst[j]=im\n",
    "            mslst[j]=ms\n",
    "            j=j+1\n",
    "            imlst[j]=imRotate\n",
    "            mslst[j]=msRotate\n",
    "            j=j+1\n",
    "            imlst[j]=imFlippedLR\n",
    "            mslst[j]=msFlippedLR\n",
    "            j=j+1\n",
    "            imlst[j]=imFlippedTB\n",
    "            mslst[j]=msFlippedTB\n",
    "            j=j+1\n",
    "    print(j)\n",
    "    return imlst,mslst\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training, test, validation split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    img,msk=load_img()\n",
    "    \n",
    "    print(\"Spleet Data..\")\n",
    "    # Split dataset in train 80% e test 20%\n",
    "    imgTrain,imgTest,mskTrain, mskTest = train_test_split(img,msk, test_size = 0.25)\n",
    "    # Split dal train il validation il 20% \n",
    "    # train, validation = train_test_split(train, test_size = 0.25)\n",
    "\n",
    "    #return train,test,validation\n",
    "    return imgTrain,mskTrain, imgTest, mskTest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load path..\n",
      "Load image..\n",
      "0\n",
      "Spleet Data..\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17782/3536816014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train,test,validation=split_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimgTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmskTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmskTest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmskTrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmskTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmskTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimgTrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17782/938660031.py\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Spleet Data..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Split dataset in train 80% e test 20%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimgTrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmskTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmskTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Split dal train il validation il 20%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# train, validation = train_test_split(train, test_size = 0.25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "#train,test,validation=split_data()\n",
    "imgTrain,mskTrain, imgTest, mskTest=split_data()\n",
    "mskTrain=mskTrain.reshape((mskTrain.shape[0],256,256,1))\n",
    "imgTrain=imgTrain.reshape((imgTrain.shape[0],256,256,3))\n",
    "print(imgTrain.shape)\n",
    "print(mskTrain.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unet:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Il problema era innanzitutto nello shape delle maskere perche io pensavo che (None,256,256) fosse uguale a (None,256,256,1) invece no.\n",
    " Inoltre nella segmentazione la rete deve generare in output non 1 valore come nelle MLP, ma una immagine di uguale dimensione a quella in input\n",
    " se ho 256,256,3 in input, in output deve avere per funzionare 256,256,1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-implementazione Unet per capire la propagazione dell'immagine con i vari re-size dovuti alla convoluzione ed al pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet:\n",
    "    def __init__(self):\n",
    "\n",
    "        inputs = tf.keras.layers.Input((256, 256, 3))\n",
    "\n",
    "        # Encoder\n",
    "        c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "        #c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "        c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "        #b1 = tf.keras.layers.BatchNormalization()(c1)\n",
    "        r1 = tf.keras.layers.ReLU()(c1)\n",
    "        p1 = tf.keras.layers.MaxPooling2D((2, 2))(r1)\n",
    "\n",
    "        c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "        #c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "        c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "        #b2 = tf.keras.layers.BatchNormalization()(c2)\n",
    "        r2 = tf.keras.layers.ReLU()(c2)\n",
    "        p2 = tf.keras.layers.MaxPooling2D((2, 2))(r2)\n",
    "        \n",
    "        c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "        #c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "        c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "        #c3 = tf.keras.layers.BatchNormalization()(c3)\n",
    "        r3 = tf.keras.layers.ReLU()(c3)\n",
    "        p3 = tf.keras.layers.MaxPooling2D((2, 2))(r3)\n",
    "        \n",
    "        c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "        #c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "        c4 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "        #b4 = tf.keras.layers.BatchNormalization()(c4)\n",
    "        r4 = tf.keras.layers.ReLU()(c4)\n",
    "        p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(r4)\n",
    "\n",
    "        # Bridge\n",
    "        c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "        c5 = tf.keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "        u5 = tf.keras.layers.BatchNormalization()(c5)\n",
    "        u5 = tf.keras.layers.ReLU()(u5)\n",
    "        #c5 = tf.keras.layers.Dropout(0.3)(r5)\n",
    "        \n",
    "\n",
    "        # Decoder \n",
    "        u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(u5)\n",
    "        u6 = tf.keras.layers.concatenate([u6, r4])\n",
    "        c6 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "        c6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c6)\n",
    "        #u6 = tf.keras.layers.BatchNormalization()(c6)\n",
    "        u6 = tf.keras.layers.ReLU()(c6)\n",
    "\n",
    "        \n",
    "        u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(u6)\n",
    "        u7 = tf.keras.layers.concatenate([u7, r3])\n",
    "        c7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "        c7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c7)\n",
    "        #u7 = tf.keras.layers.BatchNormalization()(c7)\n",
    "        u7 = tf.keras.layers.ReLU()(c7)\n",
    "\n",
    "        \n",
    "        u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(u7)\n",
    "        u8 = tf.keras.layers.concatenate([u8, r2])\n",
    "        c8 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "        c8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c8)\n",
    "        #u8 = tf.keras.layers.BatchNormalization()(c8)\n",
    "        u8 = tf.keras.layers.ReLU()(c8)\n",
    "        \n",
    "        u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(u8)\n",
    "        u9 = tf.keras.layers.concatenate([u9, r1], axis=3)\n",
    "        c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "        c9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "        #u9 = tf.keras.layers.BatchNormalization()(c9)\n",
    "        u9 = tf.keras.layers.ReLU()(c9)\n",
    "\n",
    "        # Output\n",
    "        outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(u9)\n",
    "        \n",
    "        self.model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # For gpu\n",
    "    @jit()\n",
    "    def training(self,xtrain,ytrain):\n",
    "        self.model.fit(xtrain,ytrain,batch_size=32,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with d2l.try_gpu():\n",
    "    UNet=Unet()\n",
    "    UNet.model.summary()\n",
    "    UNet.training(imgTrain,mskTrain)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-implementazione della ResUnet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResUnet:\n",
    "    def __init__(self):\n",
    "        inputs = tf.keras.layers.Input((256,256,3))\n",
    "\n",
    "        # Encoder\n",
    "        a1 = tf.keras.layers.Conv2D(64,1,activation= \"relu\", padding= \"same\")(inputs)\n",
    "\n",
    "        e1 = tf.keras.layers.Conv2D(64,3,activation= \"relu\", padding= \"same\")(inputs)\n",
    "        b1 = tf.keras.layers.BatchNormalization()(e1)\n",
    "        r1 = tf.keras.layers.ReLU()(b1)\n",
    "        e1 = tf.keras.layers.Conv2D(64,3,activation= \"relu\", padding= \"same\")(r1)\n",
    "        e1 = tf.keras.layers.add([e1,a1])\n",
    "        m1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(e1)\n",
    "\n",
    "\n",
    "        a2 = tf.keras.layers.Conv2D(128,1,activation= \"relu\", padding= \"same\")(m1)\n",
    "        \n",
    "        b2 = tf.keras.layers.BatchNormalization()(m1)\n",
    "        r2 = tf.keras.layers.ReLU()(b2)\n",
    "        e2 = tf.keras.layers.Conv2D(128,3,activation= \"relu\", padding= \"same\")(r2)\n",
    "        b2 = tf.keras.layers.BatchNormalization()(e2)\n",
    "        r2 = tf.keras.layers.ReLU()(b2)\n",
    "        e2 = tf.keras.layers.Conv2D(128,3,activation= \"relu\", padding= \"same\")(r2)\n",
    "        e2 = tf.keras.layers.add([a2,e2])\n",
    "        m2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(e2)\n",
    "\n",
    "\n",
    "        a3 = tf.keras.layers.Conv2D(256,1,activation= \"relu\", padding= \"same\")(m2)\n",
    "\n",
    "        b3 = tf.keras.layers.BatchNormalization()(m2)\n",
    "        r3 = tf.keras.layers.ReLU()(b3)\n",
    "        e3 = tf.keras.layers.Conv2D(256,3,activation= \"relu\", padding= \"same\")(r3)\n",
    "        b3 = tf.keras.layers.BatchNormalization()(e3)\n",
    "        r3 = tf.keras.layers.ReLU()(b3)\n",
    "        e3 = tf.keras.layers.Conv2D(256,3,activation= \"relu\", padding= \"same\")(r3)\n",
    "        e3 = tf.keras.layers.add([a3,e3])\n",
    "        m3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(e3)\n",
    "\n",
    "\n",
    "        # Bridge\n",
    "        a4 = tf.keras.layers.Conv2D(512,1,activation= \"relu\", padding= \"same\")(m3)\n",
    "\n",
    "        b4 = tf.keras.layers.BatchNormalization()(m3)\n",
    "        r4 = tf.keras.layers.ReLU()(b4)\n",
    "        e4 = tf.keras.layers.Conv2D(512,3,activation= \"relu\", padding= \"same\")(r4)\n",
    "        b4 = tf.keras.layers.BatchNormalization()(e4)\n",
    "        r4 = tf.keras.layers.ReLU()(b4)\n",
    "        e4 = tf.keras.layers.Conv2D(512,3,activation= \"relu\", padding= \"same\")(r4)\n",
    "        e4 = tf.keras.layers.add([a4,e4])\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        d5 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(e4)\n",
    "        d5 = tf.keras.layers.concatenate([e3,d5])\n",
    "\n",
    "        b6 = tf.keras.layers.BatchNormalization()(d5)\n",
    "        r6 = tf.keras.layers.ReLU()(b6)\n",
    "        d6 = tf.keras.layers.Conv2D(512,3,activation= \"relu\", padding= \"same\")(r6)\n",
    "        b6 = tf.keras.layers.BatchNormalization()(d6)\n",
    "        r6 = tf.keras.layers.ReLU()(b6)\n",
    "        d6 = tf.keras.layers.Conv2D(512,3,activation= \"relu\", padding= \"same\")(r6)\n",
    "        d6 = tf.keras.layers.add([d5,d6])\n",
    "\n",
    "\n",
    "        d7 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(d6)\n",
    "        d7 = tf.keras.layers.concatenate([d7,e2])\n",
    "\n",
    "        b8 = tf.keras.layers.BatchNormalization()(d7)\n",
    "        r8 = tf.keras.layers.ReLU()(b8)\n",
    "        d8 = tf.keras.layers.Conv2D(256,3,activation= \"relu\", padding= \"same\")(r8)\n",
    "        b8 = tf.keras.layers.BatchNormalization()(d8)\n",
    "        r8 = tf.keras.layers.ReLU()(b8)\n",
    "        d8 = tf.keras.layers.Conv2D(256,3,activation= \"relu\", padding= \"same\")(r8)\n",
    "        d8 = tf.keras.layers.add([d7,d8])\n",
    "        \n",
    "\n",
    "        d9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(d8)\n",
    "        d9 = tf.keras.layers.concatenate([d9,e1])\n",
    "        \n",
    "        b10 = tf.keras.layers.BatchNormalization()(d9)\n",
    "        r10 = tf.keras.layers.ReLU()(b10)\n",
    "        d10 = tf.keras.layers.Conv2D(128,3,activation= \"relu\", padding= \"same\")(r10)\n",
    "        b10 = tf.keras.layers.BatchNormalization()(d10)\n",
    "        r10 = tf.keras.layers.ReLU()(b10)\n",
    "        d10 = tf.keras.layers.Conv2D(128,3,activation= \"relu\", padding= \"same\")(d10)\n",
    "        d10 = tf.keras.layers.add([d9,d10])\n",
    "\n",
    "\n",
    "        # Output\n",
    "        outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(d10)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs = [inputs], outputs = [outputs])\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # For gpu\n",
    "    @jit()\n",
    "    def training(self,xtrain,ytrain):\n",
    "        self.model.fit(xtrain,ytrain,batch_size=32,epochs=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training e valutazione modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with d2l.try_gpu():\n",
    "    ResUnet=ResUnet()\n",
    "    ResUnet.model.summary()\n",
    "    ResUnet.training(imgTrain,mskTrain)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with d2l.try_gpu():\n",
    "    UNet.model.evaluate(imgTest,mskTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "m = ResNet50(\n",
    "    include_top=False,\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=2,\n",
    "    weights='imagenet',\n",
    "    )\n",
    "\n",
    "m.compile(optimizer=\"adam\",loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "m.fit(x,y_train)\n",
    "m.evaluate(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
